{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "code to create graph"
      ],
      "metadata": {
        "id": "EZukJcAXEK_k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oxm4-yCfDWR_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from shapely.geometry import Point\n",
        "import matplotlib.pyplot as plt\n",
        "from geopy.distance import distance\n",
        "import plotly.graph_objects as go\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "buffer_size = 300\n",
        "n_closest = 3\n",
        "path_root_city = Path('/content')\n",
        "filename = 'data_high1.csv'\n",
        "filepath = path_root_city / filename\n",
        "filepath_subway = path_root_city / 'метро.geojson'\n",
        "filepath_bus = path_root_city / 'остановки автобусов.geojson'\n",
        "filepath_tram = path_root_city / 'остановки трамвай.geojson'\n",
        "df_squares = gpd.read_file(path_root_city / 'squares1.csv')\n",
        "df_squares['building_id'] = df_squares['building_id'].astype(int)\n",
        "\n",
        "def read_geojson(path: Path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "def extract_stops(path: Path) -> list[tuple[int, float, float]]:\n",
        "    data = read_geojson(path)\n",
        "    coords = list(map(lambda v: (int(v['properties']['osm_id']),\n",
        "                                 v['geometry']['coordinates'][0],\n",
        "                                 v['geometry']['coordinates'][1]), data['features']))\n",
        "    return coords\n",
        "\n",
        "def draw_plotly(g_):\n",
        "    import plotly.express as px\n",
        "    pos_ = nx.get_node_attributes(g_, 'coordinate')\n",
        "    nodes = list(g_.nodes())\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "    edges_text = []\n",
        "    for edge in g_.edges(data=True):\n",
        "        x0, y0 = pos_[edge[0]]\n",
        "        x1, y1 = pos_[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "        edges_text.extend([f\"Meters: {edge[2]['meters']}', f'Meters: {edge[2]['meters']}\", None])\n",
        "    nodes_data = g_.nodes(data=True)\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_text = []\n",
        "    node_colors = []\n",
        "    for node in nodes:\n",
        "        x, y = pos_[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "        attrs = nodes_data[node]\n",
        "        if attrs['label'] in {'subway', 'bus', 'tram'}:\n",
        "            node_colors.append('black')\n",
        "        else:\n",
        "            node_colors.append('green' if attrs['education'] > 0 else 'red')\n",
        "        attrs = dict(filter(lambda kv: kv[0] not in {'coordinate', 'label'}, attrs.items()))\n",
        "        node_text.append('<br>'.join(list(map(lambda kv: f'{kv[0]}: {kv[1]}', attrs.items()))))\n",
        "    fig = go.Figure()\n",
        "    df_nodes = pd.DataFrame.from_records(list(dict(nodes_data).values())).drop(columns='coordinate')\n",
        "    df_nodes['s_cnt'] = df_nodes[['kindergarten', 'bus_buf', 'school', 'tram_stop', 'subway_buf']].sum(axis=1)\n",
        "    df_nodes['color'] = 'gray'\n",
        "    df_nodes.loc[df_nodes['s_cnt'] > 0, 'color'] = 'blue'\n",
        "    df_nodes.loc[df_nodes['education'] == 1, 'color'] = 'green'\n",
        "    df_nodes.loc[df_nodes['label'].isin({'tram', 'subway', 'bus'}), 'color'] = 'black'\n",
        "    fig = px.scatter_map(df_nodes, lat=\"lon\", lon=\"lat\", hover_name=\"education\", hover_data=[\"label\", \"square\"],\n",
        "                         color=df_nodes['color'],\n",
        "                         zoom=8,\n",
        "                         height=1000)\n",
        "    fig.update_layout(map_style=\"open-street-map\")\n",
        "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
        "    fig.update_layout(\n",
        "        title='Interactive Graph with NetworkX and Plotly',\n",
        "        hovermode='closest',\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "def calculate_distances(geometry: gpd.GeoSeries, point: tuple[float, float]) -> pd.Series:\n",
        "    dst = gpd.GeoSeries([Point(point), ], crs='epsg:4326').to_crs(epsg=3857)\n",
        "    return geometry.to_crs(epsg=3857).distance(dst[0])\n",
        "\n",
        "def add_stops(\n",
        "        g_: nx.Graph,\n",
        "        positions: dict[int, tuple[float, float]],\n",
        "        stops: list[tuple[int, float, float]],\n",
        "        label: str\n",
        "):\n",
        "    geometry = [Point(xy) for xy in list(positions.values())]\n",
        "    gdf_pos = gpd.GeoDataFrame(list(zip(positions.keys(), positions.values())), columns=['id', 'geometry'], crs='epsg:4326', geometry=geometry)\n",
        "    for stop_id, lat, lon in stops:\n",
        "        distances = calculate_distances(gdf_pos.geometry, (lat, lon))\n",
        "        distances_less = distances[distances < buffer_size]\n",
        "        if distances_less.shape[0] > 0:\n",
        "            if g_.has_node(stop_id):\n",
        "                raise ValueError('The node already exists')\n",
        "            g_.add_node(stop_id, coordinate=(lat, lon),\n",
        "                        label=label, education=0, kindergarten=0, school=0, bus_buf=0, tram_stop=0, subway_buf=0,\n",
        "                        lat=lat, lon=lon)\n",
        "            for building_id in gdf_pos[distances < buffer_size]['id']:\n",
        "                g_.add_edge(building_id, stop_id, meters=0)\n",
        "\n",
        "def build_data():\n",
        "    cache_file_path = Path('/content') / filename.replace('.csv', '.pkl')\n",
        "    if cache_file_path.exists():\n",
        "        with open(cache_file_path, 'rb') as f:\n",
        "            graph = pickle.load(f)\n",
        "        return graph\n",
        "    df = pd.read_csv(filepath)\n",
        "    data_json = {'features': df.to_dict(orient='records')}\n",
        "    stops_bus = extract_stops(filepath_bus)\n",
        "    stops_tram = extract_stops(filepath_tram)\n",
        "    stops_sub = extract_stops(filepath_subway)\n",
        "    graph = nx.Graph()\n",
        "    squares_map = df_squares.set_index('building_id')['building_area'].to_dict()\n",
        "    n_count = len(data_json['features'])\n",
        "    for i, building in enumerate(data_json['features']):\n",
        "        if i % 100 == 0:\n",
        "            print(f'Calc {i} / {n_count}')\n",
        "        props = building['properties'] if 'properties' in building else building\n",
        "        building_id = props['building_id']\n",
        "        square = float(squares_map[building_id])\n",
        "        education = int(props['education'] > 0)\n",
        "        if square < 200:\n",
        "            print(f'Skip building \"{building_id}\" with square {square} and education={education}')\n",
        "            continue\n",
        "        x_source, y_source = building['x'], building['y']\n",
        "        graph.add_node(props['building_id'], coordinate=(x_source, y_source),\n",
        "                       square=square,\n",
        "                       label='Y' if props['education'] else 'N',\n",
        "                       kindergarten=props['kindergarten'],\n",
        "                       school =props['school'],\n",
        "                       bus_buf=props['bus_buf'],\n",
        "                       tram_stop=props['tram_stop'],\n",
        "                       subway_buf=props['subway_buf'],\n",
        "                       education=education,\n",
        "                       lat=x_source,\n",
        "                       lon=y_source\n",
        "                       )\n",
        "    print('The nodes was build')\n",
        "    pos_: dict[int, tuple[float, float]] = nx.get_node_attributes(graph, 'coordinate')\n",
        "    geometry = [Point(xy) for xy in list(pos_.values())]\n",
        "    gdf_pos = gpd.GeoDataFrame(list(zip(pos_.keys(), pos_.values())), columns=['id', 'geometry'], crs='epsg:4326', geometry=geometry)\n",
        "    n_count = len(pos_)\n",
        "    for i, (building_id, coord) in enumerate(pos_.items()):\n",
        "        if i % 100 == 0:\n",
        "            print(f'Calc {i} / {n_count}')\n",
        "        gdf_pos['distances'] = calculate_distances(gdf_pos.geometry, coord)\n",
        "        indices = (gdf_pos['distances'] > 0) & (gdf_pos['distances'] < buffer_size)\n",
        "        if indices.any():\n",
        "            gdf_close = gdf_pos[gdf_pos['distances'] < buffer_size]\n",
        "        else:\n",
        "            gdf_close = gdf_pos.sort_values('distances')[1:n_closest]\n",
        "        was_added_any = False\n",
        "        for next_building_id, meters in zip(gdf_close['id'], gdf_close['distances']):\n",
        "            if next_building_id == building_id:\n",
        "                continue\n",
        "            graph.add_edge(building_id, next_building_id, meters=meters)\n",
        "            was_added_any = True\n",
        "        if not was_added_any:\n",
        "            raise ValueError('...')\n",
        "    print('The graph was build')\n",
        "    add_stops(graph, pos_, stops_bus, 'bus')\n",
        "    print('The bus were added')\n",
        "    add_stops(graph, pos_, stops_tram, 'tram')\n",
        "    print('The tram were added')\n",
        "    add_stops(graph, pos_, stops_sub, 'subway')\n",
        "    print('The subway were added')\n",
        "    with open(cache_file_path, 'wb') as f:\n",
        "        pickle.dump(graph, f)\n",
        "    return graph\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    graph_data = build_data()\n",
        "    draw_plotly(graph_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "binary classification of graph using graph neural network GCN"
      ],
      "metadata": {
        "id": "pk5FLG7WEPFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'data_high1.pkl'\n",
        "\n",
        "def read_data() -> nx.Graph:\n",
        "    cache_file_path = Path('/content') / filename\n",
        "    with open(cache_file_path, 'rb') as f:\n",
        "        graph = pickle.load(f)\n",
        "    return graph\n",
        "\n",
        "G: nx.Graph = read_data()\n",
        "N_FEATURES = 9\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "node_mapping = {}\n",
        "for i, (node_id, node_data) in enumerate(G.nodes(data=True)):\n",
        "    node_mapping[node_id] = i\n",
        "    is_stop = 0\n",
        "    if node_data['label'] == 'bus':\n",
        "        is_stop = 1\n",
        "    elif node_data['label'] == 'tram':\n",
        "        is_stop = 2\n",
        "    elif node_data['label'] == 'subway':\n",
        "        is_stop = 3\n",
        "    features.append([\n",
        "        node_data.get('square', 1),\n",
        "        node_data.get('building_area', 1),\n",
        "        node_data.get('living_area', 1),\n",
        "        node_data.get('population_balanced', 1),\n",
        "        node_data['school'],\n",
        "        node_data['kindergarten'],\n",
        "        node_data['bus_buf'],\n",
        "        node_data['tram_stop'],\n",
        "        node_data['subway_buf'],\n",
        "    ])\n",
        "    labels.append(int(node_data['education'] > 0))\n",
        "\n",
        "features = torch.tensor(features, dtype=torch.float)\n",
        "num_nodes = features.size(0)\n",
        "labels = torch.tensor(labels, dtype=torch.long)\n",
        "train_indices, test_indices = train_test_split(\n",
        "    np.arange(num_nodes),\n",
        "    test_size=0.3,\n",
        "    stratify=labels.numpy(),\n",
        "    random_state=21\n",
        ")\n",
        "edges = list(map(lambda v: (node_mapping[v[0]], node_mapping[v[1]]), G.edges))\n",
        "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "data = Data(x=features, edge_index=edge_index, y=labels,\n",
        "            train_mask=train_indices, test_mask=test_indices)\n",
        "assert edge_index.max() < num_nodes, \"Edge index is out of bounds!\"\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(N_FEATURES, 32)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(32)\n",
        "        self.conv2 = GCNConv(32, 64)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
        "        self.conv3 = GCNConv(64, 128)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(128)\n",
        "        self.conv4 = GCNConv(128, 256)\n",
        "        self.bn4 = torch.nn.BatchNorm1d(256)\n",
        "        self.conv5 = GCNConv(256, 512)\n",
        "        self.bn5 = torch.nn.BatchNorm1d(512)\n",
        "        self.conv6 = GCNConv(512, 1024)\n",
        "        self.bn6 = torch.nn.BatchNorm1d(1024)\n",
        "        self.conv7 = GCNConv(1024, 2)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = self.bn4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv5(x, edge_index)\n",
        "        x = self.bn5(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv6(x, edge_index)\n",
        "        x = self.bn6(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv7(x, edge_index)\n",
        "        return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = GCN().to(device)\n",
        "data = data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "class_weights = torch.tensor([1., 10.])\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "def calc_scores(out_, target_) -> tuple[float, float, float]:\n",
        "    out_max = out_.max(1)[1]\n",
        "    correct = target_.eq(out_max).sum().item()\n",
        "    acc = correct / target_.size()[0]\n",
        "    correct1 = target_[target_.eq(1)].eq(out_max[target_.eq(1)]).sum().item()\n",
        "    acc1 = correct1 / target_[target_.eq(1)].size()[0]\n",
        "    f1 = float(f1_score(target_.numpy(), out_max.numpy(), average='macro'))\n",
        "    return f1, acc, acc1\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        model.eval()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        model.train()\n",
        "        f1_train, acc_train, acc1_train = calc_scores(out[data.train_mask], data.y[data.train_mask])\n",
        "        f1_test, acc_test, acc1_test = calc_scores(out[data.test_mask], data.y[data.test_mask])\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}, '\n",
        "              f'f1/train: {f1_train:.2f}, acc/avg/train: {acc_train:.2f}, acc/1/train: {acc1_train:.2f}, '\n",
        "              f'f1/test: {f1_test:.2f}, acc/avg/test: {acc_test:.2f}, acc/1/test: {acc1_test:.2f}')\n",
        "\n",
        "def save_to_qgis(data_, pred_):\n",
        "    data_out = []\n",
        "    for i, (node_id, node_data) in enumerate(G.nodes(data=True)):\n",
        "        data_out.append([\n",
        "            node_id,\n",
        "            node_data['label'],\n",
        "            node_data.get('square', 1),\n",
        "            node_data['kindergarten'],\n",
        "            node_data['school'],\n",
        "            node_data['bus_buf'],\n",
        "            node_data['tram_stop'],\n",
        "            node_data['subway_buf'],\n",
        "            node_data['label'],\n",
        "            node_data['education'],\n",
        "            node_data['coordinate'][1],\n",
        "            node_data['coordinate'][0],\n",
        "            pred_[i]\n",
        "        ])\n",
        "    df_out = pd.DataFrame(data_out, columns=['building_id', 'label', 'square', 'kindergarten', 'school', 'bus_buf', 'subway_buf', 'tram_stop',\n",
        "                                              'label', 'education', 'lat', 'lon', 'predict'])\n",
        "    print('saving...')\n",
        "    df_out.iloc[data_.train_mask].to_csv('/content/train2.csv', index=False)\n",
        "    df_out.iloc[data_.test_mask].to_csv('/content/test2.csv', index=False)\n",
        "\n",
        "model_filename = 'model.pth'\n",
        "torch.save(model.state_dict(), model_filename)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred = model(data.x, data.edge_index)\n",
        "    f1, acc_test, acc1_test = calc_scores(pred[data.test_mask], data.y[data.test_mask])\n",
        "    save_to_qgis(data, pred.max(1)[1].numpy())\n",
        "    print(f'TEST: f1: {f1:.2f}, acc/avg/test: {acc_test:.2f}, acc/1/test: {acc1_test:.2f}')"
      ],
      "metadata": {
        "id": "YWv4T-oSEbnK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}